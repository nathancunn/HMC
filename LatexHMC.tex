\title{Simulation using Hamiltonian Monte Carlo}
\author{
        Ho Chung Leon  Law \\
            \and
        Nathan Cunningham\\
}
\date{\today}

\documentclass[12pt]{article}

\begin{document}
\maketitle

\begin{abstract}
In this report we aim to examine the properties of Hamiltonian Monte Carlo, implement it in the R coding language, and compare its effectiveness to another method of monte carlo simulation. \ldots
\end{abstract}

\section{Introduction}
Hamiltonian Monte Carlo is a markov chain monte carlo method for simulating a random sample from a probability distribution which may not be feasible to simulate from directly. \cite{Neal}
\subsection{Aim}
Our aims in this report are to:

\begin{enumerate}
\item Implement Hamiltonian Monte Carlo in the R coding language 
\item Examine the impact of the tuning parameters, $\epsilon$ and $L$, and methods of choosing these 
\item Compare Hamiltonian Monte Carlo to the Metropolis-Hastings algorithm
\end{enumerate}


\subsection{Motivation}
In cases of a multi-modal distribution many MCMC methods, including Metropolis-Hastings, can tend too much towards a local maximum and fail to explore the sample space. Hamiltonian Monte Carlo aims to get over this issue.
(comparison graphics of MH and HMC exploring sample space)

\section{Hamiltonian dynamics}
The Hamiltonian equations model the evolution of a particle in a frictionless system over time, $t$, given its momentum, $p$, and position, $q$. The Hamilton equation consists of the potential energy of the particle, $U(q)$, and the kinetic energy, $K(p)$, and in Hamiltonian Monte Carlo is usually written as
\begin{equation}
H(q,p) = U(q) + K(p)
\end{equation}
This system evolves according to the following differential equations:
\begin{equation}
\frac{dq_{i}}{dt} = \frac{\delta H}{\delta p_{i}}
\end{equation}
\begin{equation}
\frac{dp_{i}}{dt} = \frac{-\delta H}{\delta q_{i}}
\end{equation}



\subsection{Properties of Hamiltonian dynamics}

\paragraph{Reversibility}
\paragraph{Volume preservation}
\paragraph{Conservation of the Hamiltonian}
\paragraph{Symplecticness}
\subsection{The Leapfrog}
In order for the Hamiltonian dynamics to be programmed the time involved needs to be discretised. This can be done via Euler's equations (but some problems here) and is implemented using the leapfrog.
First advance the momentum by one half-step:
\begin{equation}
p_{i}(t+\epsilon/2) = p_{i}(t) - (\epsilon/2)\frac{\delta U}{\delta q_{i}}(q(t))
\end{equation}
then advance the position by a full-step using the updated momentum:
\begin{equation}
q_{i}(t+\epsilon) = q_{i}(t) - (\epsilon)\frac{p_{i}(t+\epsilon/2)}{m_{i}}
\end{equation}
And finally advance the momentum one half-step using the updated position:
\begin{equation}
p_{i}(t+\epsilon) = p_{i}(t+\epsilon/2) - (\epsilon/2)\frac{\delta U}{\delta q_{i}}(q(t+\epsilon))
\end{equation}
Iterate over this process $L$ times.

\section{Algorithm}
\begin{equation}
P(x) = \frac{1}{Z}exp(-E(x)/T)
\end{equation}
\begin{equation}
P(q,p) = \frac{1}{Z}exp(-H(q,p)/T)
\end{equation}
\begin{equation}
P(q,p) = \frac{1}{Z}exp(-U(q)/T)exp(-K(p)/T)
\end{equation}
\begin{equation}
K(p) = \sum_{i=1}^{d} \frac{p_{i}^{2}}{2m_{i}}
\end{equation}
\begin{equation}
min\{1,exp(-H(q^{*},p^{*})+H(q,p))\} = min\{1, exp(-U(q^{*}+U(q)-K(p^{*}+K(p))\}
\end{equation}
\subsection{Pseudo-code}

\section{Comparisons}
\subsection{2-d Gaussian vs MH}
\subsection{Awkward initialisations}
\subsection{Computation times}
\subsection{High-dimensionality}
\subsection{Choices of $\epsilon$ and L}

\section{No U-turn sampler (NUTS)}

\begin{thebibliography}{9}

\bibitem{neal}
  Radford M. Neal,
  \emph{MCMC using Hamiltonian dynamics},
  Chapter 5 of the Handbook of Markov Chain Monte Carlo,
  2012.

\end{thebibliography}
\end{document}
